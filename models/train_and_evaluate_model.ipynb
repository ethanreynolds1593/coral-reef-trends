{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b0510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping non-numeric columns: ['Region', 'Site_Code', 'Site_name_x', 'Habitat', 'Subregion', 'Site_name_y']\n",
      "Random Forest Results:\n",
      "MAE: 0.1059\n",
      "RMSE: 0.1460\n",
      "R²: 0.9976\n",
      "\n",
      "XGBoost Results:\n",
      "MAE: 0.0717\n",
      "RMSE: 0.1316\n",
      "R²: 0.9980\n",
      "\n",
      "⏱ Total runtime: 1451.83 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# --- Load Data ---\n",
    "stations_data = pd.read_csv('../data/processed_data/CREMP_Stations_2023.csv')\n",
    "temperatures_data = pd.read_csv('../data/processed_data/CREMP_Temperatures_2023.csv')\n",
    "\n",
    "# --- Downcast Numeric Columns ---\n",
    "for df in [stations_data, temperatures_data]:\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "# --- Convert all object columns to category ---\n",
    "for df in [stations_data, temperatures_data]:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "# --- Impute Missing Values ---\n",
    "imputer_numeric = SimpleImputer(strategy='mean')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "for df in [stations_data, temperatures_data]:\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    cat_cols = df.select_dtypes(include=['category']).columns\n",
    "    df[numeric_cols] = imputer_numeric.fit_transform(df[numeric_cols])\n",
    "    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
    "\n",
    "# --- Encode Categoricals Safely ---\n",
    "label_encoder = LabelEncoder()\n",
    "for df in [stations_data, temperatures_data]:\n",
    "    cat_cols = df.select_dtypes(include=['category']).columns\n",
    "    for col in cat_cols:\n",
    "        df[col] = label_encoder.fit_transform(df[col].astype(str))\n",
    "\n",
    "# --- Merge Datasets ---\n",
    "merged_data = pd.merge(stations_data, temperatures_data, on='SiteID', how='inner')\n",
    "\n",
    "# --- Optional: Sample for Speed ---\n",
    "merged_data = merged_data.sample(frac=0.5, random_state=42)\n",
    "\n",
    "# --- Drop Irrelevant or Problematic Columns ---\n",
    "drop_cols = ['OID_', 'Site_name', 'StationID', 'latDD', 'lonDD', \n",
    "             'latDeg', 'latMin', 'lonDeg', 'lonMin', 'row_index']\n",
    "X = merged_data.drop(columns=['TempC'] + drop_cols, errors='ignore')\n",
    "y = merged_data['TempC']\n",
    "\n",
    "# --- Ensure all features are numeric ---\n",
    "non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"Dropping non-numeric columns: {list(non_numeric_cols)}\")\n",
    "    X = X.drop(columns=non_numeric_cols)\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Random Forest Model ---\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_rf):.4f}\\n\")\n",
    "\n",
    "# --- XGBoost Model ---\n",
    "xgb_model = XGBRegressor(n_estimators=50, learning_rate=0.1, max_depth=4,\n",
    "                         subsample=0.8, colsample_bytree=0.8,\n",
    "                         random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Results:\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_xgb)):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_xgb):.4f}\\n\")\n",
    "\n",
    "print(f\"⏱ Total runtime: {time.time() - start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b6b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1cbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
